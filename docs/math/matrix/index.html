<!DOCTYPE html>
<html lang="en-gb">

<head>
  <meta name="generator" content="Hugo 0.80.0" />
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Matrizen | Escape Velocity</title>

  
  
  
  
  
  

  

  <meta name="author" content="Christina Unger">


  <meta property="og:title" content="Matrizen" />
<meta property="og:description" content="Matrizen, deren Eigenschaften und Interpretationen" />
<meta property="og:type" content="article" />
<meta property="og:url" content="http://cunger.github.io/docs/math/matrix/" />
<meta property="article:published_time" content="2020-08-26T00:00:00+00:00" />
<meta property="article:modified_time" content="2020-08-26T00:00:00+00:00" />

  




  
  
  
  
  

  <link rel="canonical" href="http://cunger.github.io/docs/math/matrix/">  

  <link href="/css/font.css" rel="stylesheet" type="text/css">
  <link href="/css/kube.css" rel="stylesheet" type="text/css">
  <link href="/css/highlight.css" rel="stylesheet" type="text/css">
  <link href="/css/master.css" rel="stylesheet" type="text/css">
  
 <link href="/css/custom.css" rel="stylesheet" type="text/css">
  
  <script src="/js/jquery-2.1.4.min.js" type="text/javascript">
  </script>

  <script type="text/javascript" src="/js/tocbot.min.js"></script>

  
  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script>
  
</head>

<body class="page-kube">
  <header> <div class="show-sm">
    <div id="nav-toggle-box">
      <div id="nav-toggle-brand">
        <a href="/">Escape Velocity</a>
      </div><a data-component="toggleme" data-target="#top" href="#" id="nav-toggle"><i class="kube-menu"></i></a>
    </div>
  </div>
  <div class="hide-sm" id="top">
    <div id="top-brand">
      <a href="/" title="home">Escape Velocity</a>
    </div>
    <nav id="top-nav-main">
      <ul>
       
       <li><a href="/docs/math/">Math</a></li>
       <li><a href="/docs/physics/">Physics</a></li>
       <li><a href="/docs/nuke/">Nuclear engineering</a></li>
       <li><a href="/docs/dev">Software development</a></li>
       <li><a href="/blog/">Blog</a></li>
       <li><a href="/about">About</a></li>
      </ul>
    </nav>
    <nav id="top-nav-extra">
      <ul>
        
      </ul>
    </nav>
  </div>
 </header>
  <main>
  <div id="main">
    <div id="hero">
      <h1> Matrizen </h1>
      <p class="hero-lead">
         Matrizen, deren Eigenschaften und Interpretationen
      </p>

    </div>
    <div id="kube-component" class="content">
    
<nav id="contents">
    <ol class="js-toc">
    </ol>
</nav>
<script type="text/javascript">
document.addEventListener("DOMContentLoaded",
function(){
tocbot.init({

tocSelector: '.js-toc',

contentSelector: '.content',

headingSelector: 'h1'
})
}
);
</script>




    <p>Eine 
<span>
                  
        \(m\times n\)
    
</span>
-Matrix über einem Körper 
<span>
                  
        \(\mathbb{K}\)
    
</span>
 ist eine Anordnung von Element von 
<span>
                  
        \(\mathbb{K}\)
    
</span>
 nach folgendem Schema (mit 
<span>
                  
        \(m\)
    
</span>
 Zeilen und 
<span>
                  
        \(n\)
    
</span>
 Spalten):

<span>
     
        $$\begin{pmatrix} a_{11} &amp; \ldots &amp; a_{1n} \\ \vdots &amp; \cdots &amp; \vdots \\ a_{m1} &amp; \ldots &amp; a_{mn} \end{pmatrix}$$
    
</span>
</p>
<p>Die Menge aller solcher Matrizen wird mit 
<span>
                  
        \(M_{mn}(\mathbb{K})\)
    
</span>
 bezeichnet.</p>
<p>Matrizen können auch über einem kommutativen Ring statt einem Körper definiert werden. Dann ergeben sich folgende Unterschiede:</p>
<ul>
<li>Matrizen über kommutativen Ringen können nicht notwendigerweise in Normalform überführt werden.</li>
</ul>
<h1 id="matrizenrechnung">Matrizenrechnung</h1>
<p>Addition und Skalarmultiplikation passieren elementweise.</p>
<p>Multiplikation</p>
<p>Transponierte Matrix</p>
<h2 id="elementarmatrizen">Elementarmatrizen</h2>
<p>Elementare Zeilenumformungen:</p>
<ul>
<li>
<span>
                  
        \(P_{ij}\)
    
</span>
 Vertauschen der Zeilen 
<span>
                  
        \(i\)
    
</span>
 und 
<span>
                  
        \(j\)
    
</span>
</li>
<li>
<span>
                  
        \(D_{i}(c)\)
    
</span>
 Multiplikation der Zeile 
<span>
                  
        \(i\)
    
</span>
 mit einem Skalar 
<span>
                  
        \(c\)
    
</span>
</li>
<li>
<span>
                  
        \(T_{ij}(c)\)
    
</span>
 Addition des 
<span>
                  
        \(c\)
    
</span>
-fachen der Zeile 
<span>
                  
        \(j\)
    
</span>
 zu einer anderen (nicht derselben!) Zeile 
<span>
                  
        \(i\)
    
</span>
</li>
</ul>
<p>Analog für Spalten. Diese Umformungen ändern den Rang einer Matrix nicht.</p>
<h1 id="rang-inverse-determinante-adjungierte">Rang, Inverse, Determinante, Adjungierte</h1>
<h2 id="rang">Rang</h2>
<p>Der <strong>Rang</strong> einer Matrix ist die Anzahl linear unabhängiger Spalten (oder Zeilen, das kommt auf&rsquo;s gleiche raus).</p>
<h2 id="determinante">Determinante</h2>
<p>Die <strong>Determinante</strong> ist eine eindeutige Abbildung 
<span>
                  
        \(M_{nn}(\mathbb{K})\to\mathbb{K}\)
    
</span>
, die so definiert ist, dass sie genau dann 0 wird, wenn die Spalten der Matrix nicht linear unabhängig sind (die Matrix also nicht invertierbar ist):

<span>
     
        $$\text{det}(A) = ...$$
    
</span>
</p>
<p>Für 
<span>
                  
        \(A\in M_{22}(\mathbb{K})\)
    
</span>
 ist das einfach:

<span>
     
        $$\text{det}(A) = a_{11} a_{22} - a_{12} a_{21}$$
    
</span>

Das lässt sich gut nachvollziehen, denn wenn die Spaltenvektoren linear abhängig sind (und von 0 verschieden), heißt das es gibt ein 
<span>
                  
        \(c\in\mathbb{K}\)
    
</span>
, so dass:

<span>
     
        $$\begin{pmatrix} a_{11} \\ a_{12} \end{pmatrix} = c\cdot \begin{pmatrix} a_{21} \\ a_{22} \end{pmatrix}$$
    
</span>

Also 
<span>
                  
        \(a_{11} = c\cdot a_{21}\)
    
</span>
 und 
<span>
                  
        \(a_{12} = c\cdot a_{22}\)
    
</span>
,
d.h. 
<span>
                  
        \(c=\dfrac{a_{11}}{a_{21}}\)
    
</span>
 und damit 
<span>
                  
        \(a_{12} = \dfrac{a_{11}}{a_{21}} a_{22}\)
    
</span>
. Daraus ergibt sich 
<span>
                  
        \(a_{12} a_{21} = a_{11} a_{22}\)
    
</span>
 bzw. 
<span>
                  
        \(0 = a_{11} a_{22} - a_{12} a_{21}\)
    
</span>
.</p>
<p>Die Determinante hat die folgenden Eigenschaften:</p>
<ul>
<li>
<p>
<span>
                  
        \(\text{det}(I)=1\)
    
</span>
 (Identitätsmatrix)</p>
</li>
<li>
<p>
<span>
                  
        \(\text{det}(AB)=\text{det}(A)\,\text{det}(B)\)
    
</span>
 für Matrizen über Integritätsbereichen</p>
</li>
<li>
<p>
<span>
                  
        \(\text{det}(A)=0\)
    
</span>
 genau dann, wenn 
<span>
                  
        \(\text{rang}(A) &lt; n\)
    
</span>
</p>
<p>Ob 
<span>
                  
        \(\text{det}(A)=0\)
    
</span>
 oder nicht ändert sich also nicht durch Zeilenumformungen. Die Determinanten ist damit eine Invariante der Matrix.</p>
<p>Für Elementarmatrizen gilt:</p>
<ul>
<li>
<span>
                  
        \(\text{det}(P_{ij}) = -1\)
    
</span>
, also

<span>
                  
        \(\text{det}(P_{ij}A)=-\text{det}(A)\)
    
</span>
</li>
<li>
<span>
                  
        \(\text{det}(D_{i}(c)) = c\)
    
</span>
, also

<span>
                  
        \(\text{det}(D_{i}(c)A)=c\cdot\text{det}(A)\)
    
</span>
</li>
<li>
<span>
                  
        \(\text{det}(T_{ij}(c)) = 1\)
    
</span>
, also

<span>
                  
        \(\text{det}(T_{ij}(c)A)=\text{det}(A)\)
    
</span>
</li>
</ul>
</li>
<li>
<p>
<span>
                  
        \(\text{det}(\text{normalform}(A))\)
    
</span>
 = Produkt der Diagonalelemente</p>
<p>Die Determinante wird also genau dann 0, wenn das Produkt der Diagonalelemente der Normalform 0 ist, d.h. wenn mindestens eins der Diagonalelemente 0 ist. Die Determinanten erfasst damit, ob eine quadratische Matrix invertierbar (regulär) ist.</p>
</li>
</ul>
<h2 id="adjungierte">Adjungierte</h2>
<h2 id="invertierbarkeit">Invertierbarkeit</h2>
<p>Für eine 
<span>
                  
        \(n\times n\)
    
</span>
 Matrix 
<span>
                  
        \(A\)
    
</span>
 sind die folgenden Aussagen äquivalent:</p>
<ul>
<li>
<span>
                  
        \(A\)
    
</span>
 ist invertierbar.</li>
<li>
<span>
                  
        \(\text{rang}(A)=n\)
    
</span>
</li>
<li>Die Spaltenvektoren von 
<span>
                  
        \(A\)
    
</span>
 sind linear unabhängig.</li>
<li>
<span>
                  
        \(A\)
    
</span>
 kann als endliches Produkt von Elementarmatrizen ausgedrückt werden.</li>
<li>
<span>
                  
        \(\text{det}(A)\neq 0\)
    
</span>
 (d.h. wenn 
<span>
                  
        \(\text{det}(A)\)
    
</span>
 im Körper oder Ring, über dem die Matriz definiert ist, invertierbar ist)</li>
</ul>
<p>Gilt 
<span>
                  
        \(AB=C\)
    
</span>
 und wendet man die gleichen Zeilenumformungen auf 
<span>
                  
        \(A\)
    
</span>
 und 
<span>
                  
        \(C\)
    
</span>
 an (mit dem Ergebnis 
<span>
                  
        \(A&#39;\)
    
</span>
 und 
<span>
                  
        \(C&#39;\)
    
</span>
), so ist 
<span>
                  
        \(A&#39;B=C&#39;\)
    
</span>
. Da 
<span>
                  
        \(AA^{-1}=I\)
    
</span>
, bedeutet das, dass man die Inverse einer Matrix bestimmen kann, indem man die gleichen Zeilenumformungen, die 
<span>
                  
        \(A\)
    
</span>
 in 
<span>
                  
        \(I\)
    
</span>
 überführen, ausführen kann, um 
<span>
                  
        \(I\)
    
</span>
 in 
<span>
                  
        \(A^{-1}\)
    
</span>
 zu überführen.</p>
<h1 id="matrizen-als-lineare-transformationen">Matrizen als lineare Transformationen</h1>
<p>Eine Matrix 
<span>
                  
        \(A\in M_{mn}(\mathbb{K})\)
    
</span>
 kann als lineare Abbildung zwischen endlichen Vektorräumen verstanden werden (
<span>
                  
        \(\mathbb{K}^n\to\mathbb{K}^m\)
    
</span>
 ), bildet also Vektoren 
<span>
                  
        \(x\in\mathbb{K}^n\)
    
</span>
 auf Vektoren 
<span>
                  
        \(Ax\in\mathbb{K}^m\)
    
</span>
 ab.
Linear ist eine solche Abbildung, weil die Matrizenmultiplikation sowohl Addition als auch Skalarmultiplikation respektiert:</p>
<ul>
<li>
<span>
                  
        \(A(x&#43;y) = Ax &#43; Ay\)
    
</span>
</li>
<li>
<span>
                  
        \(A(cx) = c(Ax)\)
    
</span>
</li>
</ul>
<p>In einem zweidimensionalen Raum kann man Linearität anschaulich so verstehen, dass die Transformation des Raumes seine Gridlinien parallel lässt und der Abstand zwischen ihnen überall gleich bleibt.</p>
<p>Da jeder Vektor als Linearkombination der kanonischen Basisvektoren dargestellt werden kann, ist eine lineare Abbildung zwischen Vektorräumen vollständig dadurch bestimmt, worauf diese Basisvektoren abgebildet werden.
Eine Matrix als Darstellung einer linearen Abbildung enthält als Spalten nun genau die Vektoren, auf die die Basisvektoren abgebildet werden.
Nehmen wir die kanonischen Basisvektoren von 
<span>
                  
        \(x\in\mathbb{K}^n\)
    
</span>
:

<span>
     
        $$e_1 = \begin{pmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{pmatrix}, \ldots, e_n = \begin{pmatrix} 0 \\ \vdots \\ 0 \\ 1 \end{pmatrix}$$
    
</span>
</p>
<p>Multiplikation einer Matrix 
<span>
                  
        \(A\)
    
</span>
 mit einem Basisvektor 
<span>
                  
        \(e_i\)
    
</span>
 ergibt genau die i-te Spalte der Matrix, d.h. 
<span>
                  
        \(Ae_i\)
    
</span>
 ist der Vektor, auf den 
<span>
                  
        \(e_i\)
    
</span>
 abgebildet wird.</p>
<p>Allgemeiner bedeutet die Multiplikation der Matrix 
<span>
                  
        \(A\)
    
</span>
 mit einem beliebigen Vektor 
<span>
                  
        \(x\)
    
</span>
 die Anwendung der Transformation auf diesen Vektor.
Denn jeder Vektor kann als Linearkombination von Basisvektoren geschrieben werden kann, aufgrund der Linearität erhält man also:

<span>
     
        $$Ax=A(c_1e_1&#43;\cdots &#43;c_ne_n)=c_1Ae_1&#43;\cdots &#43; c_nAe_n$$
    
</span>
</p>
<p>Aus der Interpretation von Matrizen als lineare Transformationen ergibt sich folgendes Bild:</p>
<ul>
<li>
<p>Die Elementarmatrizen entsprechen Basistransformationen (Rotation, Verschieben, Stauchen oder Strecken) und dass jede Matrix als Produkt von Elementarmatrizen darstellbar ist, bedeutet dass eine Transformation als Komposition von Basistransformationen beschrieben werden kann.</p>
</li>
<li>
<p>Die <strong>Matrizenmultiplikation</strong> 
<span>
                  
        \(AB\)
    
</span>
 entspricht der Komposition der beiden Transformationen (
<span>
                  
        \(A\circ B\)
    
</span>
, d.h. erst wird 
<span>
                  
        \(B\)
    
</span>
 ausgeführt, dann 
<span>
                  
        \(A\)
    
</span>
).</p>
</li>
<li>
<p>Die <strong>Inverse</strong> einer Matrix entspricht der inversen Transformation:</p>
<ul>
<li>
<span>
                  
        \(Ax=v\)
    
</span>
 bedeutet, dass die Tranformation 
<span>
                  
        \(A\)
    
</span>
 den Vektor 
<span>
                  
        \(x\)
    
</span>
 auf den Vektor 
<span>
                  
        \(v\)
    
</span>
 abbildet.</li>
<li>Daraus folgt 
<span>
                  
        \(x=A^{-1}v\)
    
</span>
, d.h. man findet 
<span>
                  
        \(x\)
    
</span>
, indem man die inverse Transformation 
<span>
                  
        \(A^{-1}\)
    
</span>
 auf 
<span>
                  
        \(v\)
    
</span>
 anwendet.</li>
</ul>
</li>
<li>
<p>Der <strong>Rang</strong> einer Matrix entspricht der Anzahl des Dimensionen des Outputs der Transformation.</p>
</li>
<li>
<p>Die <strong>Determinante</strong> einer Matrix ist der Faktor, um den ein Teil des Raumes durch die Transformation gestaucht oder gestreckt wird (z.B. der Inhalt einer Fläche im zweidimensionalen Raum oder das Volumen im dreidimensionalen Raum).</p>
<ul>
<li>Ist die Determinante negativ, entspricht das einer Umkehrung der Orientierung des Raumes.</li>
<li>Ist die Determinante 0, heißt das, die Transformation bildet auf eine niedrigere Dimension ab. Man verliert also Informationen und kann die Transformation deswegen nicht rückgängig machen, d.h. die Matrix ist nicht invertierbar.</li>
</ul>
</li>
</ul>
<h1 id="matrizen-als-gleichungssysteme">Matrizen als Gleichungssysteme</h1>
<h1 id="charakteristische-polynome-von-matrizen">Charakteristische Polynome von Matrizen</h1>


    
    </div>
  </div>
</main>
  <footer> <footer id="footer">
  <nav>
    <ul>
      <li><span>2021 (c) Christina Unger</span></li>
      <li>
        Rendered with <a href="https://gohugo.io/">Hugo</a>. Theme based on <a href="https://kube.elemnts.net/">Kube</a>.
      </li>
    </ul>
  </nav>
</footer>
 </footer>

  <script src="/js/kube.js" type="text/javascript">
  </script>
  <script src="/js/kube.legenda.js" type="text/javascript">
  </script>
  <script src="/js/master.js" type="text/javascript">
  </script>
</body>

</html>
